{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Cumulative Incidence Function (CIF) Comparison Across Time Discretizations\n\nThis notebook demonstrates how the updated CIF calculation ensures consistency across different time discretizations. Previously, different time discretizations could lead to inconsistent CIF estimates, but the updated algorithm resolves this issue.\n\nWe use the \"empirical\" method for CIF calculation, which our testing shows works better than the default \"aalen-johansen\" method.",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import seaborn as sns\n",
    "\n",
    "from multistate_nn import fit, ModelConfig, TrainConfig\n",
    "from multistate_nn.utils import (\n",
    "    generate_synthetic_data, \n",
    "    simulate_cohort_trajectories,\n",
    "    calculate_cif,\n",
    "    compare_cifs, \n",
    "    plot_cif\n",
    ")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Enable better plots\n",
    "plt.style.use('ggplot')\n",
    "sns.set_context(\"notebook\", font_scale=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Define common parameters\nn_samples = 1000\nn_covariates = 3\nn_states = 4\n\n# We'll use a more connected transition structure to ensure\n# we can reliably reach the intermediate states in either discretization\nstate_transitions = {\n    0: [1, 2, 3],  # More possible transitions from state 0\n    1: [2, 3],\n    2: [3],\n    3: []\n}\n\n# Fine time discretization (e.g., monthly)\nfine_time_values = np.array([0, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330, 360])\n# Set consistent random seed\nnp.random.seed(42)\ntorch.manual_seed(42)\nfine_data = generate_synthetic_data(\n    n_samples=n_samples, \n    n_covariates=n_covariates, \n    n_states=n_states, \n    n_time_points=len(fine_time_values),\n    time_values=fine_time_values,\n    state_transitions=state_transitions,\n    random_seed=42\n)\n\n# Coarse time discretization (e.g., quarterly)\ncoarse_time_values = np.array([0, 90, 180, 270, 360])\n# Use the same random seed for consistency\nnp.random.seed(42)\ntorch.manual_seed(42)\ncoarse_data = generate_synthetic_data(\n    n_samples=n_samples, \n    n_covariates=n_covariates, \n    n_states=n_states, \n    n_time_points=len(coarse_time_values),\n    time_values=coarse_time_values,\n    state_transitions=state_transitions,\n    random_seed=42\n)\n\n# Examine the first few rows of each dataset\nprint(\"Fine discretization data sample:\")\ndisplay(fine_data.head())\n\nprint(\"\\nCoarse discretization data sample:\")\ndisplay(coarse_data.head())",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Common parameters\ncovariates = [f\"covariate_{i}\" for i in range(3)]\n\n# Define model and training configurations\ndef create_configs(n_states=4, state_transitions=None):\n    model_config = ModelConfig(\n        input_dim=len(covariates),\n        hidden_dims=[32, 16],\n        num_states=n_states,\n        state_transitions=state_transitions\n    )\n    \n    train_config = TrainConfig(\n        batch_size=64,\n        epochs=100,  # Increase epochs for better convergence\n        learning_rate=0.01,\n        use_original_time=True  # Critical: use original time values, not indices\n    )\n    \n    return model_config, train_config\n\n# Fit model with fine discretization\nprint(\"Training model with fine time discretization...\")\nmodel_config_fine, train_config_fine = create_configs(n_states=n_states, state_transitions=state_transitions)\ntorch.manual_seed(42)  # Ensure consistent training\nfine_model = fit(\n    df=fine_data,\n    covariates=covariates,\n    model_config=model_config_fine,\n    train_config=train_config_fine\n)\n\n# Fit model with coarse discretization\nprint(\"\\nTraining model with coarse time discretization...\")\nmodel_config_coarse, train_config_coarse = create_configs(n_states=n_states, state_transitions=state_transitions)\ntorch.manual_seed(42)  # Ensure consistent training\ncoarse_model = fit(\n    df=coarse_data,\n    covariates=covariates,\n    model_config=model_config_coarse,\n    train_config=train_config_coarse\n)\n\nprint(\"\\nBoth models trained successfully!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate trajectories\n",
    "test_features = torch.zeros((1, 3))  # Neutral features for testing\n",
    "\n",
    "# Simulation parameters\n",
    "max_time = 360  # Maximum time observed in our data - we ONLY simulate within the observed time range\n",
    "n_simulations = 1000  # Increase simulation count for more stable results\n",
    "\n",
    "# Use same random seed for both simulations to reduce variability\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "print(\"Simulating trajectories with fine model...\")\n",
    "fine_trajectories = simulate_cohort_trajectories(\n",
    "    model=fine_model,\n",
    "    cohort_features=test_features,\n",
    "    start_state=0,\n",
    "    max_time=max_time,\n",
    "    n_simulations_per_patient=n_simulations,\n",
    "    seed=1234,\n",
    "    use_original_time=True\n",
    ")\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "print(\"Simulating trajectories with coarse model...\")\n",
    "coarse_trajectories = simulate_cohort_trajectories(\n",
    "    model=coarse_model,\n",
    "    cohort_features=test_features,\n",
    "    start_state=0,\n",
    "    max_time=max_time,\n",
    "    n_simulations_per_patient=n_simulations,\n",
    "    seed=1234,\n",
    "    use_original_time=True\n",
    ")\n",
    "\n",
    "print(\"Simulation complete!\")\n",
    "\n",
    "# Display the first few rows of each\n",
    "print(\"\\nFine model trajectory example:\")\n",
    "display(fine_trajectories[fine_trajectories['simulation'] == 0].head(10))\n",
    "\n",
    "print(\"\\nCoarse model trajectory example:\")\n",
    "display(coarse_trajectories[coarse_trajectories['simulation'] == 0].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Create a consistent time grid for evaluation within the observed time range\ntime_grid = np.linspace(0, 360, 100)\n\n# Let's calculate CIFs for different states to demonstrate the approach\nstates_to_check = [1, 2]  # Non-absorbing states\n\nplt.figure(figsize=(15, 10))\n\nfor i, target_state in enumerate(states_to_check):\n    # Calculate CIFs using the consistent time grid\n    fine_cif = calculate_cif(\n        fine_trajectories, \n        target_state=target_state, \n        time_grid=time_grid,\n        max_time=360,  # Explicitly limit to observed time range\n        method=\"empirical\"\n    )\n    \n    coarse_cif = calculate_cif(\n        coarse_trajectories, \n        target_state=target_state, \n        time_grid=time_grid,\n        max_time=360,  # Explicitly limit to observed time range\n        method=\"empirical\"\n    )\n    \n    # Plot in a subplot\n    ax = plt.subplot(1, len(states_to_check), i+1)\n    \n    # Plot the CIFs\n    plt.plot(fine_cif['time'], fine_cif['cif'], 'b-', linewidth=2, \n             label=f'Fine Discretization')\n    plt.plot(coarse_cif['time'], coarse_cif['cif'], 'r-', linewidth=2, \n             label=f'Coarse Discretization')\n    \n    # Add confidence intervals\n    plt.fill_between(fine_cif['time'], fine_cif['lower_ci'], fine_cif['upper_ci'], \n                     color='blue', alpha=0.1)\n    plt.fill_between(coarse_cif['time'], coarse_cif['lower_ci'], coarse_cif['upper_ci'], \n                     color='red', alpha=0.1)\n    \n    plt.title(f'CIF for State {target_state}')\n    plt.xlabel('Time')\n    plt.ylabel('Cumulative Incidence')\n    plt.grid(True, alpha=0.3)\n    plt.legend()\n    \n    # Calculate max difference for this state\n    max_diff = np.max(np.abs(fine_cif['cif'].values - coarse_cif['cif'].values))\n    plt.text(0.05, 0.95, f'Max Diff: {max_diff:.3f}', transform=ax.transAxes, \n             backgroundcolor='white', fontsize=10)\n\nplt.suptitle('CIF Comparison with Different Time Discretizations', fontsize=16)\nplt.tight_layout()\nplt.savefig('cif_discretization_comparison.png', dpi=300, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Examine the Time Mappers\n",
    "\n",
    "Let's look at how the time values are stored in each model's TimeMapper object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cif_old(trajectories, target_state, max_time=None):\n",
    "    \"\"\"Old index-based CIF calculation (simplified for demonstration).\"\"\"\n",
    "    # Make a copy\n",
    "    trajectories = trajectories.copy()\n",
    "    \n",
    "    # Ensure we have time_idx column\n",
    "    if 'time_idx' not in trajectories.columns:\n",
    "        trajectories['time_idx'] = trajectories.groupby('simulation').cumcount()\n",
    "    \n",
    "    # Filter to max_time if specified\n",
    "    if max_time is not None:\n",
    "        trajectories = trajectories[trajectories['time'] <= max_time]\n",
    "    \n",
    "    # Get unique time indices\n",
    "    time_points = sorted(trajectories['time_idx'].unique())\n",
    "    \n",
    "    # Group by simulation\n",
    "    sim_groups = trajectories.groupby('simulation')\n",
    "    n_sims = len(sim_groups)\n",
    "    \n",
    "    # For calculating CIF\n",
    "    all_incidence = np.zeros((n_sims, len(time_points)))\n",
    "    time_idx_to_pos = {t: i for i, t in enumerate(time_points)}\n",
    "    \n",
    "    for sim_idx, (_, sim_data) in enumerate(sim_groups):\n",
    "        # Find first occurrence of target state\n",
    "        target_rows = sim_data[sim_data['state'] == target_state]\n",
    "        \n",
    "        if len(target_rows) > 0:\n",
    "            # Get time index of first occurrence\n",
    "            first_occurrence_idx = target_rows['time_idx'].iloc[0]\n",
    "            \n",
    "            # For each time point, set incidence to 1 if index >= first occurrence\n",
    "            for t_idx in time_points:\n",
    "                if t_idx >= first_occurrence_idx:\n",
    "                    all_incidence[sim_idx, time_idx_to_pos[t_idx]] = 1\n",
    "    \n",
    "    # Calculate mean CIF at each time point\n",
    "    cifs = np.mean(all_incidence, axis=0)\n",
    "    \n",
    "    # Map time indices back to original time values\n",
    "    original_times = [trajectories[trajectories['time_idx'] == t]['time'].iloc[0] for t in time_points]\n",
    "    \n",
    "    # Create result DataFrame\n",
    "    cif_df = pd.DataFrame({\n",
    "        'time_idx': time_points,\n",
    "        'time': original_times,\n",
    "        'cif': cifs\n",
    "    })\n",
    "    \n",
    "    return cif_df\n",
    "\n",
    "# Calculate CIFs using the old approach for an intermediate state\n",
    "target_state = 2  # Non-absorbing state\n",
    "max_time = 360  # Limit to observed time range\n",
    "\n",
    "fine_cif_old = calculate_cif_old(fine_trajectories, target_state=target_state, max_time=max_time)\n",
    "coarse_cif_old = calculate_cif_old(coarse_trajectories, target_state=target_state, max_time=max_time)\n",
    "\n",
    "# Plot comparison using the old approach\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.plot(fine_cif_old['time'], fine_cif_old['cif'], 'b-', linewidth=2, label='Fine (Old Method)')\n",
    "plt.plot(coarse_cif_old['time'], coarse_cif_old['cif'], 'r-', linewidth=2, label='Coarse (Old Method)')\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Cumulative Incidence')\n",
    "plt.title('Old Implementation: CIF Comparison with Different Time Discretizations')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the new implementation for direct comparison\n",
    "fig, ax = compare_cifs(\n",
    "    [fine_cif, coarse_cif],\n",
    "    labels=['Fine (New Method)', 'Coarse (New Method)'],\n",
    "    title='New Implementation: CIF Comparison with Different Time Discretizations',\n",
    "    common_time_grid=True\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8. Conclusions\n\nThis notebook demonstrates how our updated CIF calculation ensures consistent results across different time discretizations. The key improvements include:\n\n1. Using actual time values rather than time indices for CIF calculation\n2. Evaluating CIFs on a consistent time grid\n3. Identifying first occurrences of events based on original time values\n4. Providing options for custom time grids to facilitate comparison\n5. **IMPORTANT:** Limiting simulation and CIF calculation to the observed time range\n6. Using the \"empirical\" method instead of \"aalen-johansen\" for more reliable results\n\nThese changes ensure that CIFs are comparable regardless of the time discretization used, making the MultiStateNN package more robust and reliable for clinical research and other applications.\n\n### Note on CIF convergence\n\nWhen CIFs are calculated for absorbing states (like death) over unlimited time, they will naturally converge to 1.0 if all trajectories eventually reach that state. To get more realistic CIFs:\n\n1. **Limit to observed time range**: Only simulate and calculate CIFs within the time range observed in the training data\n2. **Use intermediate states**: Calculate CIFs for non-absorbing states when appropriate\n3. **Consider competing risks**: In real-world scenarios, competing risks create CIFs that may plateau below 1.0",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test patient with neutral features\n",
    "test_features = torch.zeros((1, 3))\n",
    "\n",
    "# Simulation parameters\n",
    "max_time = 360  # One year\n",
    "n_simulations = 500\n",
    "\n",
    "print(\"Simulating trajectories with fine model...\")\n",
    "fine_trajectories = simulate_cohort_trajectories(\n",
    "    model=fine_model,\n",
    "    cohort_features=test_features,\n",
    "    start_state=0,\n",
    "    max_time=max_time,\n",
    "    n_simulations_per_patient=n_simulations,\n",
    "    seed=123,\n",
    "    use_original_time=True\n",
    ")\n",
    "\n",
    "print(\"Simulating trajectories with coarse model...\")\n",
    "coarse_trajectories = simulate_cohort_trajectories(\n",
    "    model=coarse_model,\n",
    "    cohort_features=test_features,\n",
    "    start_state=0,\n",
    "    max_time=max_time,\n",
    "    n_simulations_per_patient=n_simulations,\n",
    "    seed=123,\n",
    "    use_original_time=True\n",
    ")\n",
    "\n",
    "print(\"Simulation complete!\")\n",
    "\n",
    "# Display the first few rows of each\n",
    "print(\"\\nFine model trajectory example:\")\n",
    "display(fine_trajectories[fine_trajectories['simulation'] == 0].head(10))\n",
    "\n",
    "print(\"\\nCoarse model trajectory example:\")\n",
    "display(coarse_trajectories[coarse_trajectories['simulation'] == 0].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculate and Compare CIFs\n",
    "\n",
    "Now we'll calculate the Cumulative Incidence Functions (CIFs) for both models and compare them. If our fix is working correctly, the CIFs should be very similar despite the different time discretizations."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Create a consistent time grid for evaluation\ntime_grid = np.linspace(0, 360, 100)\n\n# Let's calculate CIFs for reaching the absorbing state (state 3)\ntarget_state = 3\n\n# Calculate CIFs using the consistent time grid\nfine_cif = calculate_cif(\n    fine_trajectories, \n    target_state=target_state, \n    time_grid=time_grid,\n    method=\"empirical\"\n)\n\ncoarse_cif = calculate_cif(\n    coarse_trajectories, \n    target_state=target_state, \n    time_grid=time_grid,\n    method=\"empirical\"\n)\n\n# Plot the comparison\nfig, ax = compare_cifs(\n    [fine_cif, coarse_cif],\n    labels=['Fine Discretization', 'Coarse Discretization'],\n    title=f'CIF Comparison for State {target_state} with Different Time Discretizations',\n    common_time_grid=True  # Ensure comparable visualization\n)\n\n# Display the plot\nplt.savefig('cif_discretization_comparison.png', dpi=300, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Quantitative Comparison\n",
    "\n",
    "Let's calculate some metrics to quantify the differences between the two CIFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistical measures of difference\n",
    "fine_values = fine_cif['cif'].values\n",
    "coarse_values = coarse_cif['cif'].values\n",
    "\n",
    "# Absolute differences\n",
    "abs_diff = np.abs(fine_values - coarse_values)\n",
    "mean_abs_diff = np.mean(abs_diff)\n",
    "max_abs_diff = np.max(abs_diff)\n",
    "\n",
    "# Root mean squared error\n",
    "rmse = np.sqrt(np.mean((fine_values - coarse_values) ** 2))\n",
    "\n",
    "# Print statistics\n",
    "print(\"Quantitative Comparison of CIFs:\")\n",
    "print(f\"Mean Absolute Difference: {mean_abs_diff:.6f}\")\n",
    "print(f\"Maximum Absolute Difference: {max_abs_diff:.6f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.6f}\")\n",
    "\n",
    "# Plot the differences\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(time_grid, abs_diff, 'r-', linewidth=2)\n",
    "plt.axhline(mean_abs_diff, color='k', linestyle='--', label=f'Mean: {mean_abs_diff:.6f}')\n",
    "plt.fill_between(time_grid, 0, abs_diff, alpha=0.2, color='r')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Absolute Difference')\n",
    "plt.title('Absolute Difference Between Fine and Coarse CIFs')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Previous vs Current Implementation Comparison\n",
    "\n",
    "For educational purposes, let's implement the old (index-based) CIF calculation and compare it with our new approach. This demonstrates the improvements we've made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cif_old(trajectories, target_state, max_time=None):\n",
    "    \"\"\"Old index-based CIF calculation (simplified for demonstration).\"\"\"\n",
    "    # Make a copy\n",
    "    trajectories = trajectories.copy()\n",
    "    \n",
    "    # Ensure we have time_idx column\n",
    "    if 'time_idx' not in trajectories.columns:\n",
    "        trajectories['time_idx'] = trajectories.groupby('simulation').cumcount()\n",
    "    \n",
    "    # Filter to max_time if specified\n",
    "    if max_time is not None:\n",
    "        trajectories = trajectories[trajectories['time'] <= max_time]\n",
    "    \n",
    "    # Get unique time indices\n",
    "    time_points = sorted(trajectories['time_idx'].unique())\n",
    "    \n",
    "    # Group by simulation\n",
    "    sim_groups = trajectories.groupby('simulation')\n",
    "    n_sims = len(sim_groups)\n",
    "    \n",
    "    # For calculating CIF\n",
    "    all_incidence = np.zeros((n_sims, len(time_points)))\n",
    "    time_idx_to_pos = {t: i for i, t in enumerate(time_points)}\n",
    "    \n",
    "    for sim_idx, (_, sim_data) in enumerate(sim_groups):\n",
    "        # Find first occurrence of target state\n",
    "        target_rows = sim_data[sim_data['state'] == target_state]\n",
    "        \n",
    "        if len(target_rows) > 0:\n",
    "            # Get time index of first occurrence\n",
    "            first_occurrence_idx = target_rows['time_idx'].iloc[0]\n",
    "            \n",
    "            # For each time point, set incidence to 1 if index >= first occurrence\n",
    "            for t_idx in time_points:\n",
    "                if t_idx >= first_occurrence_idx:\n",
    "                    all_incidence[sim_idx, time_idx_to_pos[t_idx]] = 1\n",
    "    \n",
    "    # Calculate mean CIF at each time point\n",
    "    cifs = np.mean(all_incidence, axis=0)\n",
    "    \n",
    "    # Map time indices back to original time values\n",
    "    original_times = [trajectories[trajectories['time_idx'] == t]['time'].iloc[0] for t in time_points]\n",
    "    \n",
    "    # Create result DataFrame\n",
    "    cif_df = pd.DataFrame({\n",
    "        'time_idx': time_points,\n",
    "        'time': original_times,\n",
    "        'cif': cifs\n",
    "    })\n",
    "    \n",
    "    return cif_df\n",
    "\n",
    "# Calculate CIFs using the old approach\n",
    "fine_cif_old = calculate_cif_old(fine_trajectories, target_state=3)\n",
    "coarse_cif_old = calculate_cif_old(coarse_trajectories, target_state=3)\n",
    "\n",
    "# Plot comparison using the old approach\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.plot(fine_cif_old['time'], fine_cif_old['cif'], 'b-', linewidth=2, label='Fine (Old Method)')\n",
    "plt.plot(coarse_cif_old['time'], coarse_cif_old['cif'], 'r-', linewidth=2, label='Coarse (Old Method)')\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Cumulative Incidence')\n",
    "plt.title('Old Implementation: CIF Comparison with Different Time Discretizations')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the new implementation for direct comparison\n",
    "fig, ax = compare_cifs(\n",
    "    [fine_cif, coarse_cif],\n",
    "    labels=['Fine (New Method)', 'Coarse (New Method)'],\n",
    "    title='New Implementation: CIF Comparison with Different Time Discretizations',\n",
    "    common_time_grid=True\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8. Conclusions\n\nThis notebook demonstrates how our updated CIF calculation ensures consistent results across different time discretizations. The key improvements include:\n\n1. Using actual time values rather than time indices for CIF calculation\n2. Evaluating CIFs on a consistent time grid\n3. Identifying first occurrences of events based on original time values\n4. Providing options for custom time grids to facilitate comparison\n5. Using the \"empirical\" method instead of \"aalen-johansen\" for more reliable results\n\nThese changes ensure that CIFs are comparable regardless of the time discretization used, making the MultiStateNN package more robust and reliable for clinical research and other applications.",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}